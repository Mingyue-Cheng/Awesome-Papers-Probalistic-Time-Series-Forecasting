# Awesome-Papers-Probalistic-Time-Series-Forecasting

## 不确定性的来源
时间序列的不确定性通常来源于两个主要方面：
数据不确定性（Aleatoric Uncertainty）：由内在噪声或随机性引起，例如传感器测量误差、市场波动、气象变化等。这种不确定性是不可消除的，通常用**概率分布（如高斯分布、混合密度模型）**建模。
模型不确定性（Epistemic Uncertainty）：由于数据不足或模型能力有限导致的，比如新冠疫情初期的数据有限，模型难以准确预测未来。这类不确定性可以通过贝叶斯方法或Dropout采样建模。
时间序列概率预测通常需要生成置信区间（Prediction Intervals, PI），但：

**如何同时建模两种不确定性？ 传统方法往往只能建模其中之一，例如贝叶斯 LSTM 主要处理模型不确定性，而混合密度网络（MDN）通常处理数据不确定性。
**如何保证模型的泛化能力？ 在数据不足的情况下，不确定性估计往往不稳定，可能导致过度拟合。

=====
### 时间序列的非平稳性
许多时间序列具有非平稳性（Non-stationarity），即数据的统计特性（均值、方差等）随时间变化，如：
金融市场：股价的波动在经济危机期间会剧烈增加，而在稳定时期则相对平稳。
医疗信号：病人术后血压的变化规律可能与术前完全不同。

### 不规则采样

### 外部因素影响

=====

### 计算复杂度
不确定性建模通常依赖于：

贝叶斯方法（如贝叶斯 LSTM）需要对权重进行概率建模，计算复杂度高。
蒙特卡洛采样（MC Dropout） 需要多次前向传播，增加推理时间。
Flow-Matching / 扩散模型 需要求解ODE/SDE，推理成本高于传统神经网络。
🔹 挑战：

如何权衡计算复杂度与预测精度？ 例如：
相较于Transformer，贝叶斯Transformer可能增加2-3倍计算成本。
Flow-Matching 训练时需模拟时间演化，推理阶段也依赖ODE求解，可能比LSTM 计算更慢。

如何平衡模型复杂性与可解释性？ 复杂模型（如 Flow-Matching）难以解释，而简单模型（如高斯回归）可能预测能力不足。

### 置信区间可能过宽或过窄：
过宽：提供的信息过于保守，失去预测的实用性。
过窄：容易导致真实值落在预测区间之外，置信区间无意义。
如何平衡预测区间的宽度和覆盖率？
使用 Coverage Probability (CP) 衡量区间是否能覆盖真实值。
使用 Mean Interval Width (MIW) 评估区间是否过宽。

如何确保在不同时间步置信区间合理？ 许多模型只能给出一个固定宽度的置信区间，而真实数据的方差可能是动态变化的。
如何结合不确定性自适应调整预测？ 一些方法（如分位数回归）可以生成不同时间点的区间，但可能无法捕捉复杂的不确定性模式。


